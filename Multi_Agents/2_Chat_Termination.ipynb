{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "\n",
    "config = ConfigParser()\n",
    "config.read(\"../config.ini\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = config[\"KEY\"][\"openai_key\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\n"
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 2 Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = ConversableAgent(\n",
    "        \"A\",\n",
    "        system_message=\"You are SolarA, and your are software developer\",\n",
    "        llm_config={\"config_list\": [\n",
    "                {\"model\":\"gpt-3.5-turbo\", \"api_key\":os.environ[\"OPENAI_API_KEY\"]}\n",
    "        ]},\n",
    "        human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "B = ConversableAgent(\n",
    "        \"B\",\n",
    "        system_message=\"You are SolarB, and your are software developer\",\n",
    "        llm_config={\"config_list\": [\n",
    "                {\"model\":\"gpt-3.5-turbo\", \"api_key\":os.environ[\"OPENAI_API_KEY\"]}\n",
    "        ]},\n",
    "        human_input_mode=\"NEVER\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Chat Conservation for 2 Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using max_turns to ending chat(dùng cho 2 bên)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mA\u001b[0m (to B):\n",
      "\n",
      "SolarB, let discuss about Attention Mechanism\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mB\u001b[0m (to A):\n",
      "\n",
      "Sure! Attention Mechanism is a key component in many deep learning models, particularly in natural language processing tasks such as machine translation and text summarization. It allows the model to focus on different parts of the input sequence when making predictions, rather than just looking at the entire sequence at once.\n",
      "\n",
      "The basic idea behind Attention Mechanism is to compute attention weights for each element in the input sequence. These attention weights indicate how much \"attention\" the model should pay to each element when making predictions. By incorporating these attention weights into the model's calculations, the model can better align the input and output sequences, leading to improved performance.\n",
      "\n",
      "There are different types of attention mechanisms, such as global attention, local attention, and self-attention (also known as scaled dot-product attention). Each type has its own strengths and weaknesses depending on the task at hand.\n",
      "\n",
      "Overall, Attention Mechanism has greatly improved the performance of deep learning models in various natural language processing tasks by allowing the model to focus on relevant parts of the input sequence. It has become a fundamental building block in modern deep learning architectures.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mA\u001b[0m (to B):\n",
      "\n",
      "That's a great explanation of Attention Mechanism! It's fascinating how attention mechanisms have enhanced the capabilities of deep learning models, especially in tasks involving sequential data like natural language processing.\n",
      "\n",
      "In addition to natural language processing, attention mechanisms have been successfully applied in computer vision tasks as well, such as image captioning and object detection. The ability to selectively focus on different regions of an image has proven to be instrumental in improving the performance of vision models.\n",
      "\n",
      "Researchers are continuously exploring new variations and improvements to attention mechanisms to address different challenges and improve the efficiency of models. The flexibility and interpretability provided by attention mechanisms make them a valuable tool in the deep learning toolkit for various applications.\n",
      "\n",
      "I'm curious, have you worked with attention mechanisms in your development projects, and if so, what has been your experience with implementing and tuning them?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mB\u001b[0m (to A):\n",
      "\n",
      "I'm glad you found the explanation helpful! \n",
      "\n",
      "Yes, I have worked with attention mechanisms in some of my development projects, particularly in natural language processing tasks such as machine translation and text summarization. Implementing attention mechanisms involves adding attention layers to the neural network architecture and incorporating them into the training process.\n",
      "\n",
      "One key aspect of working with attention mechanisms is tuning the hyperparameters related to the attention mechanism, such as the number of attention heads, the dimensionality of the attention vectors, and the type of attention mechanism used. Fine-tuning these hyperparameters can have a significant impact on the model's performance and convergence speed.\n",
      "\n",
      "Another important consideration when working with attention mechanisms is the interpretability of the model's attention weights. Visualizing the attention weights can provide insights into how the model is making predictions and which parts of the input sequences are being focused on. This can help in debugging the model and understanding its behavior.\n",
      "\n",
      "Overall, my experience with implementing and tuning attention mechanisms has been quite positive. They have proven to be effective in improving the performance of the models and have enabled better alignment between input and output sequences. Attention mechanisms have become a staple in many of my deep learning projects, and I continue to explore new variations and enhancements in this area.\n",
      "\n",
      "What about you? Have you had any experience working with attention mechanisms in your projects, and if so, what has been your experience?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = A.initiate_chat(\n",
    "        B,\n",
    "        message=\"SolarB, let discuss about Attention Mechanism\",\n",
    "        max_turns=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using max_consecutive_auto_reply ending chat(dùng cho 1 bên)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = ConversableAgent(\n",
    "        \"B\",\n",
    "        system_message=\"You are SolarB, and your are software developer\",\n",
    "        llm_config={\"config_list\": [\n",
    "                {\"model\":\"gpt-3.5-turbo\", \"api_key\":os.environ[\"OPENAI_API_KEY\"]}\n",
    "        ]},\n",
    "        max_consecutive_auto_reply=3,\n",
    "        human_input_mode=\"NEVER\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mA\u001b[0m (to B):\n",
      "\n",
      "SolarB, let discuss about RNN\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mB\u001b[0m (to A):\n",
      "\n",
      "Sure! Recurrent Neural Networks (RNNs) are a type of artificial neural network designed to handle sequential data. Unlike traditional feedforward neural networks, RNNs can maintain a memory of previous inputs through feedback loops, allowing them to process sequences of inputs with varying lengths.\n",
      "\n",
      "RNNs are commonly used in tasks such as natural language processing, speech recognition, time series prediction, and even in generating music or text. They are particularly well-suited for tasks where the order of the input data matters.\n",
      "\n",
      "However, RNNs can suffer from issues such as vanishing gradients, where the network has trouble learning from long sequences due to the gradient becoming extremely small as it is backpropagated through time. This has led to the development of more advanced RNN variants such as Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) networks, which are designed to alleviate these issues.\n",
      "\n",
      "Overall, RNNs are a powerful tool for processing sequential data and have many practical applications in the field of machine learning and artificial intelligence.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mA\u001b[0m (to B):\n",
      "\n",
      "That's a great overview of Recurrent Neural Networks (RNNs)! You've highlighted some key points about how RNNs work and their applications. The challenges like vanishing gradients and the solutions provided by LSTM and GRU networks are important aspects to consider when working with RNNs.\n",
      "\n",
      "As a software developer, have you had the opportunity to work with RNNs or any other types of neural networks in your projects? How do you approach implementing and optimizing neural networks in your software development work?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mB\u001b[0m (to A):\n",
      "\n",
      "As a software developer, I have indeed worked with neural networks, including RNNs, in various projects. When implementing and optimizing neural networks, I follow a systematic approach to ensure effectiveness and efficiency in the development process. Here are some key steps I typically take:\n",
      "\n",
      "1. Problem Understanding: Before diving into implementation, it's crucial to thoroughly understand the problem domain, the nature of the data, and the specific requirements of the task at hand. This helps in selecting the appropriate neural network architecture and designing the input/output layers accordingly.\n",
      "\n",
      "2. Data Preprocessing: Data preprocessing plays a critical role in the success of neural network models. I focus on tasks such as cleaning the data, handling missing values, scaling the features, encoding categorical variables, and splitting the data into training, validation, and test sets.\n",
      "\n",
      "3. Model Selection: Based on the problem requirements and the nature of the data, I choose the appropriate neural network architecture, whether it's a simple feedforward network, a Convolutional Neural Network (CNN) for image data, an RNN for sequential data, or more advanced architectures like transformers for natural language processing tasks.\n",
      "\n",
      "4. Training and Evaluation: I train the neural network model using the training dataset, monitor its performance on the validation set to prevent overfitting, and fine-tune hyperparameters such as learning rate, batch size, and regularization techniques to optimize the model's performance.\n",
      "\n",
      "5. Performance Optimization: To improve the neural network's performance, I experiment with techniques like dropout regularization, batch normalization, early stopping, and learning rate scheduling. I also leverage GPU acceleration for speeding up the training process, especially for larger models and datasets.\n",
      "\n",
      "6. Deployment and Monitoring: Once a trained model demonstrates satisfactory performance, I deploy it in the target environment, whether it's a web application, mobile app, or any other platform. I continuously monitor the model's performance in production, retraining it periodically with fresh data to ensure its effectiveness over time.\n",
      "\n",
      "By following these steps and staying updated with the latest advancements in neural network research and practice, I aim to build robust and efficient neural network solutions that deliver value in various software development projects.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mA\u001b[0m (to B):\n",
      "\n",
      "It's impressive to see your systematic approach to implementing and optimizing neural networks in your projects as a software developer. Your focus on problem understanding, data preprocessing, model selection, training and evaluation, performance optimization, and deployment and monitoring aligns well with best practices in machine learning development.\n",
      "\n",
      "The emphasis on continuous learning and staying updated with the latest advancements in neural network research is crucial for ensuring that your neural network solutions remain effective and competitive in the ever-evolving field of artificial intelligence.\n",
      "\n",
      "If you encounter any specific challenges or have any interesting insights from your experiences working with neural networks, feel free to share them. I'm here to discuss and provide assistance on any aspect of neural network development or related topics.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mB\u001b[0m (to A):\n",
      "\n",
      "Thank you for your encouraging words! Working with neural networks can indeed present various challenges and opportunities for learning and growth. One common challenge I have encountered while working with neural networks, especially complex architectures like RNNs and LSTMs, is optimizing hyperparameters effectively.\n",
      "\n",
      "Finding the right combination of hyperparameters such as learning rate, batch size, number of layers, hidden units, dropout rate, and others can significantly impact the neural network's performance and convergence speed. Tuning these hyperparameters manually can be time-consuming and resource-intensive.\n",
      "\n",
      "To address this challenge, I have explored techniques such as random search, grid search, and more advanced methods like Bayesian optimization and automated hyperparameter tuning using libraries like Optuna or Hyperopt. These automated approaches help in efficiently searching the hyperparameter space and finding optimal configurations for neural network models, saving time and improving performance.\n",
      "\n",
      "Another interesting insight I have gained from working with neural networks is the importance of interpretability and explainability, especially in scenarios where decision-making based on the neural network's predictions is critical. Techniques like feature visualization, attention mechanisms in models like transformers, and model-agnostic interpretation methods such as SHAP (SHapley Additive exPlanations) can provide insights into how neural networks make predictions and enhance their trustworthiness in practical applications.\n",
      "\n",
      "The field of neural network development is constantly evolving, with advancements in areas like self-supervised learning, transfer learning, reinforcement learning, and model compression techniques. Keeping up with these trends and incorporating them into my development workflow enables me to leverage the latest innovations and deliver cutting-edge solutions to address complex problems in software development.\n",
      "\n",
      "I appreciate your offer to discuss and provide assistance on neural network development topics, and I look forward to exchanging ideas and insights in this exciting field! Feel free to reach out if you have any specific questions or topics you'd like to explore further.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mA\u001b[0m (to B):\n",
      "\n",
      "It's great to hear about your experiences and insights regarding optimizing hyperparameters for neural networks and the importance of interpretability and explainability in model decision-making. Hyperparameter tuning can indeed be a challenging yet crucial aspect of developing high-performing neural network models, and leveraging automated techniques like random search, grid search, or more advanced methods such as Bayesian optimization can significantly streamline the process and improve model performance.\n",
      "\n",
      "Moreover, your focus on interpretability and explainability aligns well with the increasing emphasis on model transparency and trust in AI applications. Understanding how neural networks make predictions and being able to interpret their decision-making process can help build confidence in the model's outputs and facilitate insights for domain experts and stakeholders.\n",
      "\n",
      "The developments in self-supervised learning, transfer learning, reinforcement learning, and model compression techniques are indeed exciting areas that offer new possibilities for enhancing neural network capabilities and efficiency. Incorporating these advancements into your workflow showcases a commitment to staying at the forefront of neural network research and applying cutting-edge techniques to tackle complex challenges in software development.\n",
      "\n",
      "I'm glad to engage in discussions about these topics and explore further insights and innovations in the field of neural network development. If you have any specific questions, ideas, or areas of interest you'd like to delve into, feel free to share them. I'm here to support and collaborate on advancing your expertise in neural networks and machine learning.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = A.initiate_chat(\n",
    "        B,\n",
    "        message=\"SolarB, let discuss about RNN\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using is_termination_msg ending chat(dùng cho 1 bên khi có message kết thúc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = ConversableAgent(\n",
    "        \"A\",\n",
    "        system_message=\"You are SolarA, and your are software developer\",\n",
    "        llm_config={\"config_list\": [\n",
    "                {\"model\":\"gpt-3.5-turbo\", \"api_key\":os.environ[\"OPENAI_API_KEY\"]}\n",
    "        ]},\n",
    "        human_input_mode=\"NEVER\",\n",
    "        is_termination_msg= lambda msg: \"goodbye\" in msg[\"content\"].lower()\n",
    ")\n",
    "\n",
    "B = ConversableAgent(\n",
    "        \"B\",\n",
    "        system_message=\"You are SolarB, and your are software developer\",\n",
    "        llm_config={\"config_list\": [\n",
    "                {\"model\":\"gpt-3.5-turbo\", \"api_key\":os.environ[\"OPENAI_API_KEY\"]}\n",
    "        ]},\n",
    "        human_input_mode=\"NEVER\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mA\u001b[0m (to B):\n",
      "\n",
      "SolarB, Have a nice day. Goodbye\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mB\u001b[0m (to A):\n",
      "\n",
      "Thank you! Have a great day too. Goodbye!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = A.initiate_chat(\n",
    "        B,\n",
    "        message=\"SolarB, Have a nice day. Goodbye\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyJupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
